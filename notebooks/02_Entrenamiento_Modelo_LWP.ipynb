{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del Modelo Live Win Probability (LWP)\n",
    "\n",
    "**Objetivo:** Entrenar un modelo de Machine Learning que prediga la probabilidad de victoria en vivo basado en el estado actual del partido.\n",
    "\n",
    "**Datos:** 4 temporadas de Liga MX con datos 360 de StatsBomb\n",
    "\n",
    "**Salidas:** \n",
    "- `P(Victoria Local)`\n",
    "- `P(Empate)`\n",
    "- `P(Victoria Visitante)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup y Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import statsbombpy.sb as sb\n",
    "\n",
    "# PySpark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "print(f\"Setup complete - {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inicializar Spark Session con GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark with RAPIDS GPU acceleration\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LWP-Model-Training-GPU\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.rapids.sql.enabled\", \"true\") \\\n",
    "    .config(\"spark.plugins\", \"com.nvidia.spark.SQLPlugin\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Spark Master: {spark.sparkContext.master}\")\n",
    "print(f\"Spark UI: http://localhost:4040\")\n",
    "print(\"\\nSpark Configuration:\")\n",
    "for conf in spark.sparkContext.getConf().getAll():\n",
    "    if 'rapids' in conf[0].lower() or 'gpu' in conf[0].lower():\n",
    "        print(f\"  {conf[0]}: {conf[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cargar Datos Históricos de StatsBomb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liga MX competition ID\n",
    "COMPETITION_ID = 40  # Liga MX\n",
    "\n",
    "print(\"Cargando competiciones...\")\n",
    "competitions = sb.competitions()\n",
    "liga_mx = competitions[competitions['competition_id'] == COMPETITION_ID]\n",
    "print(f\"\\nTemporadas disponibles de Liga MX:\")\n",
    "print(liga_mx[['season_id', 'season_name']])\n",
    "\n",
    "# Get the last 4 seasons\n",
    "season_ids = liga_mx['season_id'].tail(4).tolist()\n",
    "print(f\"\\nTemporadas seleccionadas: {season_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all matches from the selected seasons\n",
    "all_matches = []\n",
    "\n",
    "for season_id in season_ids:\n",
    "    print(f\"\\nCargando partidos de temporada {season_id}...\")\n",
    "    matches = sb.matches(competition_id=COMPETITION_ID, season_id=season_id)\n",
    "    all_matches.append(matches)\n",
    "    print(f\"  - {len(matches)} partidos cargados\")\n",
    "\n",
    "matches_df = pd.concat(all_matches, ignore_index=True)\n",
    "print(f\"\\nTotal de partidos: {len(matches_df)}\")\n",
    "print(f\"Columnas: {matches_df.columns.tolist()}\")\n",
    "matches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering - Extracción de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_events(match_id, events_df):\n",
    "    \"\"\"\n",
    "    Extrae características para cada snapshot temporal del partido.\n",
    "    Cada fila representa el estado del partido en un momento dado.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Get match info\n",
    "    match_info = matches_df[matches_df['match_id'] == match_id].iloc[0]\n",
    "    home_team = match_info['home_team']\n",
    "    away_team = match_info['away_team']\n",
    "    home_score = match_info['home_score']\n",
    "    away_score = match_info['away_score']\n",
    "    \n",
    "    # Determine final result\n",
    "    if home_score > away_score:\n",
    "        result = 'home_win'\n",
    "    elif home_score < away_score:\n",
    "        result = 'away_win'\n",
    "    else:\n",
    "        result = 'draw'\n",
    "    \n",
    "    # Sort events by time\n",
    "    events_df = events_df.sort_values(['period', 'minute', 'second'])\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    current_home_score = 0\n",
    "    current_away_score = 0\n",
    "    home_shots = 0\n",
    "    away_shots = 0\n",
    "    home_passes = 0\n",
    "    away_passes = 0\n",
    "    \n",
    "    # Create snapshots every 5 minutes\n",
    "    for minute in range(0, 95, 5):\n",
    "        events_until_now = events_df[events_df['minute'] <= minute]\n",
    "        \n",
    "        if len(events_until_now) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Count events by team\n",
    "        home_events = events_until_now[events_until_now['team'] == home_team]\n",
    "        away_events = events_until_now[events_until_now['team'] == away_team]\n",
    "        \n",
    "        # Calculate current score\n",
    "        goals = events_until_now[events_until_now['type'] == 'Shot']\n",
    "        current_home_score = len(goals[(goals['team'] == home_team) & (goals['shot_outcome'] == 'Goal')])\n",
    "        current_away_score = len(goals[(goals['team'] == away_team) & (goals['shot_outcome'] == 'Goal')])\n",
    "        \n",
    "        # Calculate stats\n",
    "        home_shots = len(home_events[home_events['type'] == 'Shot'])\n",
    "        away_shots = len(away_events[away_events['type'] == 'Shot'])\n",
    "        home_passes = len(home_events[home_events['type'] == 'Pass'])\n",
    "        away_passes = len(away_events[away_events['type'] == 'Pass'])\n",
    "        \n",
    "        # Calculate possession (simplified)\n",
    "        total_events = len(home_events) + len(away_events)\n",
    "        home_possession = len(home_events) / total_events if total_events > 0 else 0.5\n",
    "        \n",
    "        # Create feature row\n",
    "        feature_row = {\n",
    "            'match_id': match_id,\n",
    "            'minute': minute,\n",
    "            'home_score': current_home_score,\n",
    "            'away_score': current_away_score,\n",
    "            'score_diff': current_home_score - current_away_score,\n",
    "            'home_shots': home_shots,\n",
    "            'away_shots': away_shots,\n",
    "            'shots_diff': home_shots - away_shots,\n",
    "            'home_passes': home_passes,\n",
    "            'away_passes': away_passes,\n",
    "            'passes_diff': home_passes - away_passes,\n",
    "            'home_possession': home_possession,\n",
    "            'time_remaining': 90 - minute,\n",
    "            'result': result\n",
    "        }\n",
    "        \n",
    "        features.append(feature_row)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from all matches\n",
    "print(\"Extrayendo características de los partidos...\")\n",
    "print(\"Nota: Este proceso puede tomar varios minutos debido a las llamadas a la API.\\n\")\n",
    "\n",
    "all_features = []\n",
    "match_ids = matches_df['match_id'].head(50).tolist()  # Use first 50 matches for training\n",
    "\n",
    "for i, match_id in enumerate(match_ids, 1):\n",
    "    try:\n",
    "        print(f\"[{i}/{len(match_ids)}] Procesando match {match_id}...\", end=\" \")\n",
    "        events = sb.events(match_id=match_id, split=False, flatten_attrs=True)\n",
    "        features = extract_features_from_events(match_id, events)\n",
    "        all_features.extend(features)\n",
    "        print(f\"✓ {len(features)} snapshots\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error: {e}\")\n",
    "        continue\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "features_pd = pd.DataFrame(all_features)\n",
    "print(f\"\\nTotal de snapshots (filas): {len(features_pd)}\")\n",
    "print(f\"Distribución de resultados:\")\n",
    "print(features_pd['result'].value_counts())\n",
    "features_pd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparar Datos para Entrenamiento en Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas DataFrame to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(features_pd)\n",
    "\n",
    "print(\"Spark DataFrame creado:\")\n",
    "spark_df.printSchema()\n",
    "print(f\"\\nNúmero de filas: {spark_df.count()}\")\n",
    "spark_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "feature_cols = [\n",
    "    'minute', 'home_score', 'away_score', 'score_diff',\n",
    "    'home_shots', 'away_shots', 'shots_diff',\n",
    "    'home_passes', 'away_passes', 'passes_diff',\n",
    "    'home_possession', 'time_remaining'\n",
    "]\n",
    "\n",
    "# Create vector assembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Create label indexer (convert string labels to numeric)\n",
    "label_indexer = StringIndexer(\n",
    "    inputCol=\"result\",\n",
    "    outputCol=\"label\"\n",
    ")\n",
    "\n",
    "# Transform data\n",
    "data_with_features = assembler.transform(spark_df)\n",
    "data_with_labels = label_indexer.fit(data_with_features).transform(data_with_features)\n",
    "\n",
    "print(\"Datos preparados para entrenamiento:\")\n",
    "data_with_labels.select('features', 'label', 'result').show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "train_data, test_data = data_with_labels.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Training set: {train_data.count()} filas\")\n",
    "print(f\"Test set: {test_data.count()} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entrenar Modelo de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Forest classifier\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    numTrees=100,\n",
    "    maxDepth=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Entrenando modelo Random Forest con GPU...\")\n",
    "print(\"Revisa Spark UI en http://localhost:4040 para métricas de rendimiento\\n\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "rf_model = rf.fit(train_data)\n",
    "training_time = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "print(f\"✓ Modelo entrenado en {training_time:.2f} segundos\")\n",
    "print(f\"✓ Número de árboles: {rf_model.getNumTrees}\")\n",
    "print(f\"✓ Feature importances disponibles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "predictions = rf_model.transform(test_data)\n",
    "\n",
    "print(\"Predicciones del modelo:\")\n",
    "predictions.select('minute', 'score_diff', 'result', 'label', 'prediction', 'probability').show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "f1_score = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"MÉTRICAS DEL MODELO\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.featureImportances.toArray()\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nImportancia de características:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Guardar Modelo Entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to disk\n",
    "MODEL_PATH = \"/work/models/lwp_model\"\n",
    "\n",
    "print(f\"Guardando modelo en {MODEL_PATH}...\")\n",
    "rf_model.write().overwrite().save(MODEL_PATH)\n",
    "print(\"✓ Modelo guardado exitosamente\")\n",
    "\n",
    "# Save label mapping\n",
    "label_mapping = label_indexer.fit(data_with_features).labels\n",
    "print(f\"\\nMapeo de etiquetas: {label_mapping}\")\n",
    "print(\"  0 = Victoria Local (home_win)\")\n",
    "print(\"  1 = Empate (draw)\")\n",
    "print(\"  2 = Victoria Visitante (away_win)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test de Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference with sample data\n",
    "test_scenario = spark.createDataFrame([\n",
    "    # Scenario 1: Home team winning 2-0 at minute 70\n",
    "    (70, 2, 0, 2, 8, 3, 5, 250, 180, 70, 0.58, 20),\n",
    "    # Scenario 2: Tied 1-1 at minute 45\n",
    "    (45, 1, 1, 0, 5, 5, 0, 200, 200, 0, 0.50, 45),\n",
    "    # Scenario 3: Away team leading 0-1 at minute 80\n",
    "    (80, 0, 1, -1, 6, 8, -2, 280, 220, -60, 0.56, 10),\n",
    "], feature_cols)\n",
    "\n",
    "test_features = assembler.transform(test_scenario)\n",
    "test_predictions = rf_model.transform(test_features)\n",
    "\n",
    "print(\"Test de inferencia con escenarios de ejemplo:\")\n",
    "test_predictions.select(\n",
    "    'minute', 'score_diff', 'home_possession', 'time_remaining',\n",
    "    'prediction', 'probability'\n",
    ").show(truncate=False)\n",
    "\n",
    "print(\"\\nInterpretación de probabilidades:\")\n",
    "print(\"probability[0] = P(Victoria Local)\")\n",
    "print(\"probability[1] = P(Empate)\")\n",
    "print(\"probability[2] = P(Victoria Visitante)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Resumen y Próximos Pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RESUMEN DEL ENTRENAMIENTO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Modelo: Random Forest Classifier\")\n",
    "print(f\"✓ Datos: {len(matches_df)} partidos procesados\")\n",
    "print(f\"✓ Features: {len(feature_cols)} características\")\n",
    "print(f\"✓ Training samples: {train_data.count()}\")\n",
    "print(f\"✓ Test samples: {test_data.count()}\")\n",
    "print(f\"✓ Accuracy: {accuracy:.4f}\")\n",
    "print(f\"✓ F1 Score: {f1_score:.4f}\")\n",
    "print(f\"✓ Training time: {training_time:.2f} seconds\")\n",
    "print(f\"✓ Modelo guardado en: {MODEL_PATH}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPRÓXIMOS PASOS:\")\n",
    "print(\"1. Ejecutar notebook 03_Streaming_Estadisticas.ipynb\")\n",
    "print(\"2. Ejecutar notebook 04_Streaming_Inferencia_LWP.ipynb\")\n",
    "print(\"3. Capturar métricas desde Spark UI (localhost:4040)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "# spark.stop()\n",
    "print(\"\\nNota: Spark session sigue activa para exploración adicional.\")\n",
    "print(\"Ejecuta 'spark.stop()' cuando termines.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
