{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming: C√°lculo de Estad√≠sticas en Tiempo Real\n",
    "\n",
    "**Objetivo:** Procesar el stream de eventos de Kafka y calcular estad√≠sticas en tiempo real.\n",
    "\n",
    "**Estad√≠sticas a calcular:**\n",
    "- M√≠nimos, M√°ximos, Promedios y Varianza de:\n",
    "  - Pases por equipo\n",
    "  - Distancia recorrida\n",
    "  - Posiciones promedio\n",
    "  - Posesi√≥n\n",
    "\n",
    "**Arquitectura:** Spark Structured Streaming + RAPIDS GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"Setup complete - {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inicializar Spark Session con GPU y Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark with RAPIDS GPU acceleration and Kafka support\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StatsBomb-Streaming-Statistics-GPU\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.rapids.sql.enabled\", \"true\") \\\n",
    "    .config(\"spark.plugins\", \"com.nvidia.spark.SQLPlugin\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1\") \\\n",
    "    .config(\"spark.sql.streaming.checkpointLocation\", \"/tmp/checkpoint-stats\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(f\"‚úì Spark Version: {spark.version}\")\n",
    "print(f\"‚úì Spark Master: {spark.sparkContext.master}\")\n",
    "print(f\"‚úì Spark UI: http://localhost:4040\")\n",
    "print(\"\\nüìä Monitor Spark UI para capturar m√©tricas de rendimiento:\")\n",
    "print(\"   - Job Time\")\n",
    "print(\"   - Shuffle Read/Write\")\n",
    "print(\"   - I/O\")\n",
    "print(\"   - Scheduler Delay\")\n",
    "print(\"   - Spill (Memory/Disk)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definir Schema de Eventos de StatsBomb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for StatsBomb events\n",
    "event_schema = StructType([\n",
    "    StructField(\"event\", StructType([\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"index\", IntegerType(), True),\n",
    "        StructField(\"period\", IntegerType(), True),\n",
    "        StructField(\"timestamp\", StringType(), True),\n",
    "        StructField(\"minute\", IntegerType(), True),\n",
    "        StructField(\"second\", IntegerType(), True),\n",
    "        StructField(\"type\", StructType([\n",
    "            StructField(\"id\", IntegerType(), True),\n",
    "            StructField(\"name\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField(\"team\", StructType([\n",
    "            StructField(\"id\", IntegerType(), True),\n",
    "            StructField(\"name\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField(\"player\", StructType([\n",
    "            StructField(\"id\", IntegerType(), True),\n",
    "            StructField(\"name\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField(\"location\", ArrayType(DoubleType()), True),\n",
    "        StructField(\"pass_end_location\", ArrayType(DoubleType()), True),\n",
    "        StructField(\"under_pressure\", BooleanType(), True),\n",
    "    ]), True),\n",
    "    StructField(\"metadata\", StructType([\n",
    "        StructField(\"producer_timestamp\", StringType(), True),\n",
    "        StructField(\"producer_id\", StringType(), True)\n",
    "    ]), True)\n",
    "])\n",
    "\n",
    "print(\"‚úì Schema definido\")\n",
    "print(\"\\nEstructura del schema:\")\n",
    "event_schema.printTreeString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conectar a Kafka Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka configuration\n",
    "KAFKA_BOOTSTRAP_SERVERS = \"kafka:9092\"\n",
    "KAFKA_TOPIC = \"statsbomb-360-events\"\n",
    "\n",
    "# Read from Kafka\n",
    "kafka_stream = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BOOTSTRAP_SERVERS) \\\n",
    "    .option(\"subscribe\", KAFKA_TOPIC) \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .option(\"maxOffsetsPerTrigger\", 10000) \\\n",
    "    .load()\n",
    "\n",
    "print(f\"‚úì Conectado a Kafka: {KAFKA_BOOTSTRAP_SERVERS}\")\n",
    "print(f\"‚úì Topic: {KAFKA_TOPIC}\")\n",
    "print(f\"‚úì Stream creado\")\n",
    "\n",
    "# Parse JSON from Kafka value\n",
    "parsed_stream = kafka_stream.select(\n",
    "    col(\"timestamp\").alias(\"kafka_timestamp\"),\n",
    "    from_json(col(\"value\").cast(\"string\"), event_schema).alias(\"data\")\n",
    ").select(\n",
    "    \"kafka_timestamp\",\n",
    "    \"data.event.*\",\n",
    "    \"data.metadata.*\"\n",
    ")\n",
    "\n",
    "print(\"‚úì Stream parseado\")\n",
    "print(\"\\nColumnas disponibles:\")\n",
    "print(parsed_stream.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Procesamiento de Eventos - Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant features from events\n",
    "events_with_features = parsed_stream \\\n",
    "    .withColumn(\"event_time\", col(\"kafka_timestamp\")) \\\n",
    "    .withColumn(\"event_type\", col(\"type.name\")) \\\n",
    "    .withColumn(\"team_name\", col(\"team.name\")) \\\n",
    "    .withColumn(\"player_name\", col(\"player.name\")) \\\n",
    "    .withColumn(\"location_x\", col(\"location\").getItem(0)) \\\n",
    "    .withColumn(\"location_y\", col(\"location\").getItem(1)) \\\n",
    "    .withColumn(\"is_pass\", when(col(\"event_type\") == \"Pass\", 1).otherwise(0)) \\\n",
    "    .withColumn(\"is_shot\", when(col(\"event_type\") == \"Shot\", 1).otherwise(0)) \\\n",
    "    .withColumn(\"is_dribble\", when(col(\"event_type\") == \"Dribble\", 1).otherwise(0)) \\\n",
    "    .withColumn(\n",
    "        \"pass_distance\",\n",
    "        when(\n",
    "            col(\"pass_end_location\").isNotNull(),\n",
    "            sqrt(\n",
    "                pow(col(\"pass_end_location\").getItem(0) - col(\"location_x\"), 2) +\n",
    "                pow(col(\"pass_end_location\").getItem(1) - col(\"location_y\"), 2)\n",
    "            )\n",
    "        ).otherwise(0)\n",
    "    )\n",
    "\n",
    "print(\"‚úì Features extra√≠dos de los eventos\")\n",
    "print(\"\\nFeatures calculados:\")\n",
    "print(\"  - event_type: Tipo de evento\")\n",
    "print(\"  - team_name: Equipo\")\n",
    "print(\"  - location_x, location_y: Posici√≥n en el campo\")\n",
    "print(\"  - is_pass, is_shot, is_dribble: Flags de tipo de evento\")\n",
    "print(\"  - pass_distance: Distancia del pase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Agregaciones por Ventanas de Tiempo (1 minuto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time windows (1 minute tumbling window)\n",
    "windowed_stats = events_with_features \\\n",
    "    .withWatermark(\"event_time\", \"30 seconds\") \\\n",
    "    .groupBy(\n",
    "        window(col(\"event_time\"), \"1 minute\"),\n",
    "        col(\"team_name\")\n",
    "    ) \\\n",
    "    .agg(\n",
    "        # Pases\n",
    "        sum(\"is_pass\").alias(\"total_passes\"),\n",
    "        min(\"is_pass\").alias(\"min_passes\"),\n",
    "        max(\"is_pass\").alias(\"max_passes\"),\n",
    "        avg(\"is_pass\").alias(\"avg_passes\"),\n",
    "        stddev(\"is_pass\").alias(\"stddev_passes\"),\n",
    "        \n",
    "        # Distancia de pases\n",
    "        sum(\"pass_distance\").alias(\"total_pass_distance\"),\n",
    "        min(\"pass_distance\").alias(\"min_pass_distance\"),\n",
    "        max(\"pass_distance\").alias(\"max_pass_distance\"),\n",
    "        avg(\"pass_distance\").alias(\"avg_pass_distance\"),\n",
    "        stddev(\"pass_distance\").alias(\"stddev_pass_distance\"),\n",
    "        \n",
    "        # Posiciones promedio\n",
    "        avg(\"location_x\").alias(\"avg_position_x\"),\n",
    "        avg(\"location_y\").alias(\"avg_position_y\"),\n",
    "        stddev(\"location_x\").alias(\"stddev_position_x\"),\n",
    "        stddev(\"location_y\").alias(\"stddev_position_y\"),\n",
    "        \n",
    "        # Tiros y dribles\n",
    "        sum(\"is_shot\").alias(\"total_shots\"),\n",
    "        sum(\"is_dribble\").alias(\"total_dribbles\"),\n",
    "        \n",
    "        # Total de eventos (proxy para posesi√≥n)\n",
    "        count(\"*\").alias(\"total_events\")\n",
    "    ) \\\n",
    "    .select(\n",
    "        col(\"window.start\").alias(\"window_start\"),\n",
    "        col(\"window.end\").alias(\"window_end\"),\n",
    "        \"team_name\",\n",
    "        \"total_passes\",\n",
    "        \"min_passes\",\n",
    "        \"max_passes\",\n",
    "        \"avg_passes\",\n",
    "        \"stddev_passes\",\n",
    "        \"total_pass_distance\",\n",
    "        \"min_pass_distance\",\n",
    "        \"max_pass_distance\",\n",
    "        \"avg_pass_distance\",\n",
    "        \"stddev_pass_distance\",\n",
    "        \"avg_position_x\",\n",
    "        \"avg_position_y\",\n",
    "        \"stddev_position_x\",\n",
    "        \"stddev_position_y\",\n",
    "        \"total_shots\",\n",
    "        \"total_dribbles\",\n",
    "        \"total_events\"\n",
    "    ) \\\n",
    "    .orderBy(\"window_start\", \"team_name\")\n",
    "\n",
    "print(\"‚úì Agregaciones configuradas\")\n",
    "print(\"‚úì Ventanas: 1 minuto (tumbling window)\")\n",
    "print(\"‚úì Watermark: 30 segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Iniciar Stream - Output a Consola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start streaming query with console output\n",
    "query = windowed_stats.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .option(\"numRows\", 50) \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STREAMING ACTIVO - ESTAD√çSTICAS EN TIEMPO REAL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Query ID: {query.id}\")\n",
    "print(f\"Query Name: {query.name}\")\n",
    "print(f\"Status: {query.status}\")\n",
    "print(\"\\nüìä CAPTURA DE M√âTRICAS:\")\n",
    "print(\"   1. Abre Spark UI en http://localhost:4040\")\n",
    "print(\"   2. Ve a la pesta√±a 'Streaming'\")\n",
    "print(\"   3. Captura las siguientes m√©tricas:\")\n",
    "print(\"      - Input Rate (eventos/segundo)\")\n",
    "print(\"      - Process Rate (eventos/segundo)\")\n",
    "print(\"      - Batch Duration\")\n",
    "print(\"      - Scheduling Delay\")\n",
    "print(\"   4. Ve a la pesta√±a 'Jobs' para m√©tricas detalladas:\")\n",
    "print(\"      - Job Time\")\n",
    "print(\"      - Shuffle Read/Write\")\n",
    "print(\"      - Spill (Memory/Disk)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n‚ö†Ô∏è  Presiona el bot√≥n STOP en la celda para detener el streaming\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor query status\n",
    "import time\n",
    "\n",
    "try:\n",
    "    while query.isActive:\n",
    "        print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] Query Status: {query.status}\")\n",
    "        print(f\"Recent Progress:\")\n",
    "        \n",
    "        if query.recentProgress:\n",
    "            latest = query.recentProgress[-1]\n",
    "            print(f\"  - Batch ID: {latest.get('batchId', 'N/A')}\")\n",
    "            print(f\"  - Input Rows: {latest.get('numInputRows', 'N/A')}\")\n",
    "            print(f\"  - Process Rate: {latest.get('processedRowsPerSecond', 'N/A'):.2f} rows/sec\" if latest.get('processedRowsPerSecond') else \"  - Process Rate: N/A\")\n",
    "            print(f\"  - Duration: {latest.get('durationMs', {}).get('triggerExecution', 'N/A')} ms\")\n",
    "        \n",
    "        time.sleep(10)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è  Deteniendo streaming...\")\n",
    "    query.stop()\n",
    "    print(\"‚úì Streaming detenido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Detener Stream (ejecutar cuando sea necesario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the streaming query\n",
    "if query.isActive:\n",
    "    print(\"Deteniendo streaming query...\")\n",
    "    query.stop()\n",
    "    query.awaitTermination(timeout=30)\n",
    "    print(\"‚úì Query detenido\")\n",
    "else:\n",
    "    print(\"Query no est√° activo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resumen de M√©tricas a Capturar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"M√âTRICAS A CAPTURAR DESDE SPARK UI (localhost:4040)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. STREAMING TAB:\")\n",
    "print(\"   ‚úì Input Rate (eventos/segundo)\")\n",
    "print(\"   ‚úì Process Rate (eventos/segundo)\")\n",
    "print(\"   ‚úì Batch Duration (ms)\")\n",
    "print(\"   ‚úì Operation Duration (ms)\")\n",
    "print(\"   ‚úì Scheduling Delay (ms)\")\n",
    "print(\"\\n2. JOBS TAB:\")\n",
    "print(\"   ‚úì Job Duration\")\n",
    "print(\"   ‚úì Shuffle Read Size\")\n",
    "print(\"   ‚úì Shuffle Write Size\")\n",
    "print(\"   ‚úì Spill (Memory)\")\n",
    "print(\"   ‚úì Spill (Disk)\")\n",
    "print(\"\\n3. STAGES TAB:\")\n",
    "print(\"   ‚úì Stage Duration\")\n",
    "print(\"   ‚úì Task Deserialization Time\")\n",
    "print(\"   ‚úì GC Time\")\n",
    "print(\"   ‚úì Input Size / Records\")\n",
    "print(\"   ‚úì Output Size / Records\")\n",
    "print(\"\\n4. EXECUTORS TAB:\")\n",
    "print(\"   ‚úì Storage Memory Used\")\n",
    "print(\"   ‚úì Disk Used\")\n",
    "print(\"   ‚úì Total Tasks\")\n",
    "print(\"   ‚úì Task Time (GC Time)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüí° COMPARACI√ìN ARQUITECTURAS:\")\n",
    "print(\"   Para arquitectura 2 (CPU), tu compa√±ero debe:\")\n",
    "print(\"   1. Comentar l√≠neas de RAPIDS en spark-defaults.conf\")\n",
    "print(\"   2. Remover asignaci√≥n de GPU en docker-compose.yml\")\n",
    "print(\"   3. Re-ejecutar este mismo notebook\")\n",
    "print(\"   4. Comparar m√©tricas GPU vs CPU\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "# spark.stop()\n",
    "print(\"\\nNota: Spark session sigue activa.\")\n",
    "print(\"Ejecuta 'spark.stop()' cuando termines todas las pruebas.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
