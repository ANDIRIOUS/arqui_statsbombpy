{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming: Inferencia de Live Win Probability en Tiempo Real\n",
    "\n",
    "**Objetivo:** Aplicar el modelo de ML entrenado (LWP) al stream de eventos en vivo para predecir probabilidades de victoria en tiempo real.\n",
    "\n",
    "**Entrada:** Stream de eventos de Kafka\n",
    "\n",
    "**Salida:** Predicciones continuas de:\n",
    "- P(Victoria Local)\n",
    "- P(Empate)\n",
    "- P(Victoria Visitante)\n",
    "\n",
    "**Arquitectura:** Spark Structured Streaming + RAPIDS GPU + ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"Setup complete - {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inicializar Spark Session con GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark with RAPIDS GPU acceleration\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StatsBomb-Streaming-ML-Inference-GPU\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.rapids.sql.enabled\", \"true\") \\\n",
    "    .config(\"spark.plugins\", \"com.nvidia.spark.SQLPlugin\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1\") \\\n",
    "    .config(\"spark.sql.streaming.checkpointLocation\", \"/tmp/checkpoint-ml\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(f\"‚úì Spark Version: {spark.version}\")\n",
    "print(f\"‚úì Spark Master: {spark.sparkContext.master}\")\n",
    "print(f\"‚úì Spark UI: http://localhost:4040\")\n",
    "print(\"\\nüìä Monitor Spark UI para capturar m√©tricas de ML en streaming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cargar Modelo Entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "MODEL_PATH = \"/work/models/lwp_model\"\n",
    "\n",
    "print(f\"Cargando modelo desde {MODEL_PATH}...\")\n",
    "\n",
    "try:\n",
    "    lwp_model = RandomForestClassificationModel.load(MODEL_PATH)\n",
    "    print(\"‚úì Modelo cargado exitosamente\")\n",
    "    print(f\"‚úì N√∫mero de √°rboles: {lwp_model.getNumTrees}\")\n",
    "    print(f\"‚úì N√∫mero de features: {lwp_model.numFeatures}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error cargando modelo: {e}\")\n",
    "    print(\"\\n‚ö†Ô∏è  Aseg√∫rate de ejecutar primero el notebook 02_Entrenamiento_Modelo_LWP.ipynb\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definir Schema y Conectar a Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for StatsBomb events\n",
    "event_schema = StructType([\n",
    "    StructField(\"event\", StructType([\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"index\", IntegerType(), True),\n",
    "        StructField(\"period\", IntegerType(), True),\n",
    "        StructField(\"timestamp\", StringType(), True),\n",
    "        StructField(\"minute\", IntegerType(), True),\n",
    "        StructField(\"second\", IntegerType(), True),\n",
    "        StructField(\"type\", StructType([\n",
    "            StructField(\"id\", IntegerType(), True),\n",
    "            StructField(\"name\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField(\"team\", StructType([\n",
    "            StructField(\"id\", IntegerType(), True),\n",
    "            StructField(\"name\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField(\"player\", StructType([\n",
    "            StructField(\"id\", IntegerType(), True),\n",
    "            StructField(\"name\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField(\"location\", ArrayType(DoubleType()), True),\n",
    "        StructField(\"pass_end_location\", ArrayType(DoubleType()), True),\n",
    "    ]), True),\n",
    "    StructField(\"metadata\", StructType([\n",
    "        StructField(\"producer_timestamp\", StringType(), True),\n",
    "        StructField(\"producer_id\", StringType(), True)\n",
    "    ]), True)\n",
    "])\n",
    "\n",
    "# Kafka configuration\n",
    "KAFKA_BOOTSTRAP_SERVERS = \"kafka:9092\"\n",
    "KAFKA_TOPIC = \"statsbomb-360-events\"\n",
    "\n",
    "# Read from Kafka\n",
    "kafka_stream = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BOOTSTRAP_SERVERS) \\\n",
    "    .option(\"subscribe\", KAFKA_TOPIC) \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .option(\"maxOffsetsPerTrigger\", 10000) \\\n",
    "    .load()\n",
    "\n",
    "# Parse JSON\n",
    "parsed_stream = kafka_stream.select(\n",
    "    col(\"timestamp\").alias(\"kafka_timestamp\"),\n",
    "    from_json(col(\"value\").cast(\"string\"), event_schema).alias(\"data\")\n",
    ").select(\n",
    "    \"kafka_timestamp\",\n",
    "    \"data.event.*\",\n",
    "    \"data.metadata.*\"\n",
    ")\n",
    "\n",
    "print(\"‚úì Conectado a Kafka\")\n",
    "print(f\"‚úì Topic: {KAFKA_TOPIC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering para el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and aggregate features needed for the model\n",
    "# We need to maintain state of the match to calculate features\n",
    "\n",
    "# First, extract basic features from events\n",
    "events_with_features = parsed_stream \\\n",
    "    .withColumn(\"event_time\", col(\"kafka_timestamp\")) \\\n",
    "    .withColumn(\"event_type\", col(\"type.name\")) \\\n",
    "    .withColumn(\"team_id\", col(\"team.id\")) \\\n",
    "    .withColumn(\"team_name\", col(\"team.name\")) \\\n",
    "    .withColumn(\"is_pass\", when(col(\"event_type\") == \"Pass\", 1).otherwise(0)) \\\n",
    "    .withColumn(\"is_shot\", when(col(\"event_type\") == \"Shot\", 1).otherwise(0)) \\\n",
    "    .withColumn(\"is_goal\", when((col(\"event_type\") == \"Shot\"), 1).otherwise(0))  # Simplified\n",
    "\n",
    "print(\"‚úì Features b√°sicos extra√≠dos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate features over 2-minute windows to create match state snapshots\n",
    "# This simulates the current state of the match at each point in time\n",
    "\n",
    "match_state = events_with_features \\\n",
    "    .withWatermark(\"event_time\", \"30 seconds\") \\\n",
    "    .groupBy(\n",
    "        window(col(\"event_time\"), \"2 minutes\", \"1 minute\"),  # Sliding window\n",
    "        col(\"team_name\")\n",
    "    ) \\\n",
    "    .agg(\n",
    "        max(\"minute\").alias(\"current_minute\"),\n",
    "        sum(\"is_goal\").alias(\"goals\"),\n",
    "        sum(\"is_shot\").alias(\"shots\"),\n",
    "        sum(\"is_pass\").alias(\"passes\"),\n",
    "        count(\"*\").alias(\"events\")\n",
    "    )\n",
    "\n",
    "print(\"‚úì Estado del partido agregado por ventanas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to get home vs away team stats in the same row\n",
    "# This is a simplified version - in production, you'd need to properly identify home/away teams\n",
    "\n",
    "# For demonstration, we'll create synthetic match state features\n",
    "# In a real scenario, you'd maintain global state or use more sophisticated streaming joins\n",
    "\n",
    "features_for_model = match_state \\\n",
    "    .withColumn(\"window_start\", col(\"window.start\")) \\\n",
    "    .withColumn(\"window_end\", col(\"window.end\")) \\\n",
    "    .drop(\"window\") \\\n",
    "    .withColumn(\n",
    "        # Create a simplified match state\n",
    "        \"minute\", col(\"current_minute\")\n",
    "    ) \\\n",
    "    .withColumn(\"home_score\", col(\"goals\")) \\\n",
    "    .withColumn(\"away_score\", lit(0)) \\\n",
    "    .withColumn(\"score_diff\", col(\"goals\")) \\\n",
    "    .withColumn(\"home_shots\", col(\"shots\")) \\\n",
    "    .withColumn(\"away_shots\", lit(0)) \\\n",
    "    .withColumn(\"shots_diff\", col(\"shots\")) \\\n",
    "    .withColumn(\"home_passes\", col(\"passes\")) \\\n",
    "    .withColumn(\"away_passes\", lit(0)) \\\n",
    "    .withColumn(\"passes_diff\", col(\"passes\")) \\\n",
    "    .withColumn(\"home_possession\", lit(0.5)) \\\n",
    "    .withColumn(\"time_remaining\", lit(90) - col(\"minute\"))\n",
    "\n",
    "print(\"‚úì Features para el modelo preparados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Aplicar Modelo para Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the same feature columns used during training\n",
    "feature_cols = [\n",
    "    'minute', 'home_score', 'away_score', 'score_diff',\n",
    "    'home_shots', 'away_shots', 'shots_diff',\n",
    "    'home_passes', 'away_passes', 'passes_diff',\n",
    "    'home_possession', 'time_remaining'\n",
    "]\n",
    "\n",
    "# Create vector assembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Assemble features\n",
    "data_with_features = assembler.transform(features_for_model)\n",
    "\n",
    "# Apply model to streaming data\n",
    "predictions = lwp_model.transform(data_with_features)\n",
    "\n",
    "print(\"‚úì Modelo aplicado al stream\")\n",
    "print(\"‚úì Predicciones continuas gener√°ndose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract probabilities for better display\n",
    "predictions_formatted = predictions.select(\n",
    "    col(\"window_start\"),\n",
    "    col(\"window_end\"),\n",
    "    col(\"team_name\"),\n",
    "    col(\"minute\"),\n",
    "    col(\"score_diff\"),\n",
    "    col(\"shots_diff\"),\n",
    "    col(\"passes_diff\"),\n",
    "    col(\"prediction\"),\n",
    "    col(\"probability\"),\n",
    "    # Extract individual probabilities\n",
    "    col(\"probability\").getItem(0).alias(\"prob_class_0\"),\n",
    "    col(\"probability\").getItem(1).alias(\"prob_class_1\"),\n",
    "    col(\"probability\").getItem(2).alias(\"prob_class_2\")\n",
    ") \\\n",
    ".withColumn(\n",
    "    # Format probabilities as percentages\n",
    "    \"prediction_text\",\n",
    "    when(col(\"prediction\") == 0.0, \"HOME WIN\")\n",
    "    .when(col(\"prediction\") == 1.0, \"DRAW\")\n",
    "    .otherwise(\"AWAY WIN\")\n",
    ") \\\n",
    ".select(\n",
    "    \"window_start\",\n",
    "    \"team_name\",\n",
    "    \"minute\",\n",
    "    \"score_diff\",\n",
    "    \"shots_diff\",\n",
    "    \"passes_diff\",\n",
    "    \"prediction_text\",\n",
    "    (col(\"prob_class_0\") * 100).alias(\"P_HOME_WIN_%\"),\n",
    "    (col(\"prob_class_1\") * 100).alias(\"P_DRAW_%\"),\n",
    "    (col(\"prob_class_2\") * 100).alias(\"P_AWAY_WIN_%\")\n",
    ") \\\n",
    ".orderBy(\"window_start\")\n",
    "\n",
    "print(\"‚úì Predicciones formateadas para visualizaci√≥n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Iniciar Stream - Output de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start streaming query with console output\n",
    "query = predictions_formatted.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .option(\"numRows\", 30) \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STREAMING ML INFERENCE ACTIVO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Query ID: {query.id}\")\n",
    "print(f\"Status: {query.status}\")\n",
    "print(\"\\nü§ñ PREDICCIONES EN TIEMPO REAL:\")\n",
    "print(\"   - P_HOME_WIN_%: Probabilidad de victoria local\")\n",
    "print(\"   - P_DRAW_%: Probabilidad de empate\")\n",
    "print(\"   - P_AWAY_WIN_%: Probabilidad de victoria visitante\")\n",
    "print(\"\\nüìä CAPTURA DE M√âTRICAS:\")\n",
    "print(\"   1. Abre Spark UI en http://localhost:4040\")\n",
    "print(\"   2. Compara m√©tricas con el notebook 03 (sin ML)\")\n",
    "print(\"   3. Observa el overhead de inferencia ML:\")\n",
    "print(\"      - Batch Duration aumentado\")\n",
    "print(\"      - CPU/GPU utilization\")\n",
    "print(\"      - Memory usage\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n‚ö†Ô∏è  Presiona el bot√≥n STOP para detener el streaming\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor query status\n",
    "import time\n",
    "\n",
    "try:\n",
    "    while query.isActive:\n",
    "        print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] ML Inference Query Status\")\n",
    "        print(f\"Status: {query.status}\")\n",
    "        \n",
    "        if query.recentProgress:\n",
    "            latest = query.recentProgress[-1]\n",
    "            print(f\"Recent Progress:\")\n",
    "            print(f\"  - Batch ID: {latest.get('batchId', 'N/A')}\")\n",
    "            print(f\"  - Input Rows: {latest.get('numInputRows', 'N/A')}\")\n",
    "            print(f\"  - Process Rate: {latest.get('processedRowsPerSecond', 'N/A'):.2f} rows/sec\" if latest.get('processedRowsPerSecond') else \"  - Process Rate: N/A\")\n",
    "            print(f\"  - Duration: {latest.get('durationMs', {}).get('triggerExecution', 'N/A')} ms\")\n",
    "            print(f\"  - ML Inference Overhead: observe en Spark UI\")\n",
    "        \n",
    "        time.sleep(10)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è  Deteniendo streaming...\")\n",
    "    query.stop()\n",
    "    print(\"‚úì Streaming detenido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Detener Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the streaming query\n",
    "if query.isActive:\n",
    "    print(\"Deteniendo streaming query...\")\n",
    "    query.stop()\n",
    "    query.awaitTermination(timeout=30)\n",
    "    print(\"‚úì Query detenido\")\n",
    "else:\n",
    "    print(\"Query no est√° activo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. An√°lisis de Rendimiento y Comparaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"GU√çA DE AN√ÅLISIS DE RENDIMIENTO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. M√âTRICAS CLAVE A CAPTURAR:\")\n",
    "print(\"   üìä Streaming Tab (Spark UI):\")\n",
    "print(\"      - Input Rate vs Process Rate\")\n",
    "print(\"      - Batch Duration (con vs sin ML)\")\n",
    "print(\"      - Scheduling Delay\")\n",
    "print(\"\\n   ‚öôÔ∏è  Jobs Tab:\")\n",
    "print(\"      - Job Duration (comparar notebooks 03 vs 04)\")\n",
    "print(\"      - Shuffle metrics\")\n",
    "print(\"      - Task metrics\")\n",
    "print(\"\\n   üíæ Executors Tab:\")\n",
    "print(\"      - Memory utilization\")\n",
    "print(\"      - GPU utilization (si disponible)\")\n",
    "print(\"      - GC time\")\n",
    "print(\"\\n2. COMPARACI√ìN ARQUITECTURAS:\")\n",
    "print(\"   üîÑ Para cambiar a Arquitectura 2 (CPU):\")\n",
    "print(\"      1. Editar spark-conf/spark-defaults.conf\")\n",
    "print(\"      2. Comentar l√≠neas:\")\n",
    "print(\"         # spark.plugins=com.nvidia.spark.SQLPlugin\")\n",
    "print(\"         # spark.rapids.sql.enabled=true\")\n",
    "print(\"      3. Editar docker-compose.yml\")\n",
    "print(\"      4. Remover secciones 'deploy.resources.reservations.devices'\")\n",
    "print(\"      5. Reiniciar servicios: docker-compose down && docker-compose up -d\")\n",
    "print(\"      6. Re-ejecutar notebooks\")\n",
    "print(\"\\n3. M√âTRICAS A COMPARAR (GPU vs CPU):\")\n",
    "print(\"   ‚úì Throughput (eventos/segundo)\")\n",
    "print(\"   ‚úì Latencia promedio por batch\")\n",
    "print(\"   ‚úì Job time total\")\n",
    "print(\"   ‚úì Shuffle read/write\")\n",
    "print(\"   ‚úì Memory spill\")\n",
    "print(\"   ‚úì GC time\")\n",
    "print(\"   ‚úì CPU/GPU utilization\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n4. EXPORTAR M√âTRICAS:\")\n",
    "print(\"   - Spark UI tiene opci√≥n de exportar JSON\")\n",
    "print(\"   - Captura screenshots de gr√°ficas clave\")\n",
    "print(\"   - Usa las m√©tricas de query.recentProgress para an√°lisis\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export query metrics if available\n",
    "if hasattr(query, 'recentProgress') and query.recentProgress:\n",
    "    print(\"\\n√öltimas m√©tricas capturadas:\")\n",
    "    import json\n",
    "    \n",
    "    for i, progress in enumerate(query.recentProgress[-3:], 1):\n",
    "        print(f\"\\n--- Batch {progress.get('batchId', 'N/A')} ---\")\n",
    "        print(json.dumps(progress, indent=2))\nelse:\n",
    "    print(\"\\nNo hay m√©tricas disponibles. Ejecuta el query primero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "# spark.stop()\n",
    "print(\"\\n‚úì Notebook completado\")\n",
    "print(\"\\nNota: Spark session sigue activa.\")\n",
    "print(\"Ejecuta 'spark.stop()' cuando termines todas las pruebas.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
