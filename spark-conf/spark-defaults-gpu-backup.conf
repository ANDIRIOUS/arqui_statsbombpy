# ================================================
# Spark Defaults Configuration
# Architecture 1: RAPIDS GPU Acceleration
# ================================================
# NOTE: To switch to Architecture 2 (CPU), comment out the RAPIDS plugin lines

# ================================================
# RAPIDS GPU Plugin Configuration
# ================================================
# Enable RAPIDS Accelerator for Apache Spark
spark.plugins                           com.nvidia.spark.SQLPlugin
spark.rapids.sql.enabled                true
spark.rapids.sql.explain                ALL
spark.rapids.memory.pinnedPool.size     2G

# RAPIDS Kryo Registrator (REQUIRED for RAPIDS with Kryo)
spark.kryo.registrator                  com.nvidia.spark.rapids.GpuKryoRegistrator

# GPU Resource Configuration
spark.executor.resource.gpu.amount      1
spark.executor.resource.gpu.discoveryScript /opt/spark/getGpusResources.sh
spark.task.resource.gpu.amount          0.25

# Worker GPU Resource Configuration
spark.worker.resource.gpu.amount        1
spark.worker.resource.gpu.discoveryScript /opt/spark/getGpusResources.sh

# ================================================
# Executor and Driver Configuration
# ================================================
spark.executor.memory                   8g
spark.executor.cores                    4
spark.executor.instances                1
spark.driver.memory                     6g
spark.driver.cores                      2

# Memory Management
spark.memory.fraction                   0.8
spark.memory.storageFraction            0.3

# ================================================
# Kafka Integration Configuration
# ================================================
# Note: RAPIDS JAR is already in /opt/spark/jars, only need Kafka package
spark.jars.packages                     org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1

# Kafka Consumer Settings
spark.streaming.kafka.maxRatePerPartition 2048
spark.streaming.backpressure.enabled    true

# ================================================
# Structured Streaming Configuration
# ================================================
spark.sql.streaming.checkpointLocation  /tmp/spark-checkpoints
spark.sql.streaming.stateStore.providerClass org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider
spark.sql.streaming.metricsEnabled      true

# ================================================
# Performance Tuning
# ================================================
# Shuffle Configuration
spark.sql.shuffle.partitions            200
spark.shuffle.service.enabled           false
spark.dynamicAllocation.enabled         false

# Serialization
spark.serializer                        org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max         512m

# SQL Optimizations
spark.sql.adaptive.enabled              true
spark.sql.adaptive.coalescePartitions.enabled true
spark.sql.adaptive.skewJoin.enabled     true

# ================================================
# Spark UI and Monitoring
# ================================================
spark.ui.enabled                        true
spark.ui.port                           4040
spark.eventLog.enabled                  true
spark.eventLog.dir                      /tmp/spark-events
spark.history.fs.logDirectory           /tmp/spark-events

# Metrics Configuration (for performance comparison)
# Commented out to reduce console noise - metrics still available in Spark UI
# spark.metrics.conf.*.sink.console.class org.apache.spark.metrics.sink.ConsoleSink
# spark.metrics.conf.*.sink.console.period 10

# ================================================
# Application Configuration
# ================================================
spark.app.name                          StatsBomb-RAPIDS-Streaming
spark.master                            spark://spark-master:7077

# Network Configuration
spark.driver.host                       jupyter-lab
spark.driver.bindAddress                0.0.0.0
