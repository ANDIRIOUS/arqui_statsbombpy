# Resumen Final - Sistema Spark GPU/CPU Streaming

## âœ… Estado Actual del Sistema

**Todos los problemas han sido resueltos.** El sistema estÃ¡ completamente operativo.

### Servicios Operativos
- âœ… Zookeeper - Port 2181
- âœ… Kafka - Ports 9092, 9093
- âœ… Producer - Streaming ~3000 events/sec
- âœ… Spark Master - Port 8080, 7077
- âœ… Spark Worker - Port 8081 (GPU disponible)
- âœ… Jupyter Lab - Port 8888

### ConfiguraciÃ³n Actual
- **Modo:** GPU (RAPIDS habilitado en spark-defaults.conf)
- **Spark:** 3.3.1 Standalone
- **Executor Memory:** 8GB
- **Executor Cores:** 4
- **Executors:** 1 (forzado con spark.cores.max = 4)
- **Driver Memory:** 6GB
- **GPU Task Amount:** 1.0 (cada task usa GPU completa)
- **GPU Config:** Optimizada para evitar conflictos de executors

### Estado de Notebooks
- âœ… Notebook 02 (Training) - Completado exitosamente
- âœ… Notebook 03 (Streaming Statistics) - Corregido y listo
- âœ… Notebook 04 (Streaming ML Inference) - Corregido y listo

## ðŸ”§ Problemas Resueltos (en orden cronolÃ³gico)

### 1. Liga MX Data No Disponible
**Problema:** competition_id=40 (Liga MX) no estÃ¡ en StatsBomb open data
**SoluciÃ³n:** Cambiado a La Liga (competition_id=11) con 17 temporadas disponibles
**Archivos:** `notebooks/02_Entrenamiento_Modelo_LWP.ipynb`

### 2. pandas 2.0+ Incompatibilidad con PySpark 3.3.1
**Problema:** `AttributeError: 'DataFrame' object has no attribute 'iteritems'`
**SoluciÃ³n:** Downgrade pandas de 2.0.3 â†’ 1.5.3
**Archivos:** `jupyter/requirements.txt`
**Comando:** `docker exec jupyter-lab pip install pandas==1.5.3`

### 3. ConfiguraciÃ³n de Memoria Excedida
**Problema:** 2 executors Ã— 12GB = 24GB > 16GB disponibles
**SoluciÃ³n:** Reducido a 1 executor Ã— 8GB + driver 6GB = 14GB
**Archivos:** `spark-conf/spark-defaults.conf`

### 4. Worker Sin Recursos GPU Configurados
**Problema:** Worker no tenÃ­a `spark.worker.resource.gpu.*` configurado
**SoluciÃ³n:** Agregadas propiedades de recursos GPU del worker
**Archivos:** `spark-conf/spark-defaults.conf`

### 5. Executors Fallando con GPU
**Problema:** MÃºltiples executors intentando acceder a 1 GPU simultÃ¡neamente â†’ fallo constante
**SoluciÃ³n:** Deshabilitado RAPIDS temporalmente (modo CPU para training)
**Archivos:** `spark-conf/spark-defaults.conf` (RAPIDS comentado)
**Backup:** `spark-conf/spark-defaults-gpu-backup.conf`

### 6. Notebook 02 Forzando ConfiguraciÃ³n GPU
**Problema:** Cell 4 incluÃ­a `.config("spark.rapids.sql.enabled", "true")` hardcodeado
**SoluciÃ³n:** Actualizado notebook para usar configuraciÃ³n de spark-defaults.conf
**Archivos:** `notebooks/02_Entrenamiento_Modelo_LWP.ipynb`

### 7. Notebook 03 - printTreeString() No Existe
**Problema:** Cell 6 llamaba `event_schema.printTreeString()` que no existe en StructType
**SoluciÃ³n:** Cambiado a `print(event_schema.simpleString())`
**Archivos:** `notebooks/03_Streaming_Estadisticas.ipynb` Cell 6

### 8. Notebooks 03 y 04 Forzando ConfiguraciÃ³n GPU
**Problema:** Ambos notebooks tenÃ­an GPU config hardcodeada en Cell 4
**SoluciÃ³n:** Removida configuraciÃ³n hardcodeada, ahora usan spark-defaults.conf
**Archivos:**
  - `notebooks/03_Streaming_Estadisticas.ipynb` Cell 4
  - `notebooks/04_Streaming_Inferencia_LWP.ipynb` Cell 4

### 9. ConfiguraciÃ³n GPU Causando MÃºltiples Executors
**Problema:** `spark.task.resource.gpu.amount = 0.25` permitÃ­a mÃºltiples tasks por GPU, causando conflictos
**SoluciÃ³n:** Cambiado a `1.0` para que cada task use GPU completa + `spark.cores.max = 4` para forzar 1 solo executor
**Archivos:** `spark-conf/spark-defaults.conf`
**ConfiguraciÃ³n crÃ­tica:**
  - `spark.executor.instances = 1` (solo 1 executor)
  - `spark.cores.max = 4` (mÃ¡ximo 4 cores totales)
  - `spark.task.resource.gpu.amount = 1.0` (cada task usa GPU completa)
  - `spark.executor.resource.gpu.amount = 1` (executor usa 1 GPU)

## ðŸ“ Archivos Creados/Modificados

### Archivos de ConfiguraciÃ³n
1. **spark-conf/spark-defaults.conf** - ConfiguraciÃ³n principal (modo CPU)
2. **spark-conf/spark-defaults-gpu-backup.conf** - Backup con GPU habilitada
3. **jupyter/requirements.txt** - pandas 1.5.3
4. **docker-compose.yml** - Worker command y GPU allocation

### Notebooks
1. **notebooks/02_Entrenamiento_Modelo_LWP.ipynb** - Actualizado para:
   - Usar La Liga (competition_id=11)
   - No forzar configuraciÃ³n GPU
   - Usar configuraciÃ³n de spark-defaults.conf

2. **notebooks/03_Streaming_Estadisticas.ipynb** - Actualizado para:
   - Cell 4: Removida configuraciÃ³n GPU hardcodeada
   - Cell 6: Corregido `printTreeString()` â†’ `simpleString()`
   - Ahora usa spark-defaults.conf para GPU/CPU mode

3. **notebooks/04_Streaming_Inferencia_LWP.ipynb** - Actualizado para:
   - Cell 4: Removida configuraciÃ³n GPU hardcodeada
   - Ahora usa spark-defaults.conf para GPU/CPU mode

### DocumentaciÃ³n
1. **NOTEBOOK_FIX.md** - Problemas 1 y 2 (Liga MX y pandas)
2. **GPU_ISSUE_SOLUTION.md** - Problema 5 (executors fallando)
3. **RESTART_INSTRUCTIONS.md** - CÃ³mo reiniciar sesiones
4. **SYSTEM_STATUS.md** - Estado del sistema
5. **FINAL_SUMMARY.md** - Este archivo

## ðŸš€ CÃ³mo Proceder Ahora

### âœ… Notebook 02 (Training) - YA COMPLETADO

El usuario ya ejecutÃ³ exitosamente el notebook 02 y el modelo estÃ¡ entrenado.

### ðŸŽ¯ Notebooks 03 y 04 (Streaming) - LISTOS PARA EJECUTAR

Los notebooks de streaming estÃ¡n corregidos y listos para usar.

**ConfiguraciÃ³n actual:**
- âœ… GPU estÃ¡ habilitada (spark-defaults.conf tiene RAPIDS activo)
- âœ… Notebooks YA NO fuerzan configuraciÃ³n GPU
- âœ… Todo usa spark-defaults.conf centralizadamente
- âœ… GPU configurada para 1 executor Ãºnico (evita conflictos)
- âœ… Servicios de Spark reiniciados con nueva configuraciÃ³n

### Paso 1: Reiniciar Kernel de Jupyter

**IMPORTANTE:** Los servicios de Spark ya fueron reiniciados con la nueva configuraciÃ³n GPU optimizada.

En Jupyter Lab (http://localhost:8888):

1. **Menu â†’ Kernel â†’ Shutdown Kernel**
2. **Esperar 5 segundos**
3. **Recargar la pÃ¡gina** (F5)

### Paso 2: Ejecutar Notebook 03 (Streaming Statistics)

**Abrir:** `03_Streaming_Estadisticas.ipynb`

**Ejecutar:**
- Menu â†’ `Run` â†’ `Run All Cells`
- O cell por cell con `Shift + Enter`

**QuÃ© verÃ¡s:**
- âœ… Spark session con GPU habilitada
- âœ… ConexiÃ³n a Kafka
- âœ… EstadÃ­sticas en tiempo real (ventanas de 1 minuto)
- âœ… MÃ©tricas en Spark UI: http://localhost:4040

**DuraciÃ³n:** Corre indefinidamente hasta que presiones STOP

### Paso 3: Ejecutar Notebook 04 (Streaming ML Inference)

**DespuÃ©s de detener notebook 03:**

1. **Shutdown kernel** del notebook 03
2. **Abrir:** `04_Streaming_Inferencia_LWP.ipynb`
3. **Ejecutar:** Run All Cells

**QuÃ© verÃ¡s:**
- âœ… Carga del modelo entrenado desde `/work/models/lwp_model`
- âœ… Predicciones en tiempo real: P(Home Win), P(Draw), P(Away Win)
- âœ… MÃ©tricas de inferencia ML en Spark UI

**DuraciÃ³n:** Corre indefinidamente hasta que presiones STOP

### Paso 4: Capturar MÃ©tricas GPU (Arquitectura 1)

**En Spark UI (http://localhost:4040):**

1. **Streaming Tab:**
   - Input Rate (eventos/segundo)
   - Process Rate (eventos/segundo)
   - Batch Duration (ms)
   - Scheduling Delay (ms)

2. **Jobs Tab:**
   - Job Duration
   - Shuffle Read/Write Size
   - Spill (Memory/Disk)

3. **Executors Tab:**
   - Memory utilization
   - GC time
   - Task metrics

**Captura screenshots o exporta mÃ©tricas a JSON**

## ðŸ”„ Cambiar de GPU a CPU (Arquitectura 2)

Para comparar rendimiento GPU vs CPU, sigue estos pasos:

### Paso 1: Deshabilitar RAPIDS

```bash
# Comentar lÃ­neas de RAPIDS en spark-defaults.conf
sed -i 's/^spark.plugins/# spark.plugins/' spark-conf/spark-defaults.conf
sed -i 's/^spark.rapids.sql.enabled/# spark.rapids.sql.enabled/' spark-conf/spark-defaults.conf
sed -i 's/^spark.kryo.registrator/# spark.kryo.registrator/' spark-conf/spark-defaults.conf

# Reiniciar servicios
docker compose restart spark-master spark-worker jupyter-lab

# Esperar 10 segundos
sleep 10
```

### Paso 2: Re-ejecutar Notebooks 03 y 04

1. Shutdown kernel de Jupyter
2. Re-ejecutar notebooks 03 y 04
3. Capturar mÃ©tricas CPU en Spark UI
4. Comparar con mÃ©tricas GPU

### Paso 3: Restaurar GPU

```bash
# Des-comentar lÃ­neas de RAPIDS
sed -i 's/^# spark.plugins/spark.plugins/' spark-conf/spark-defaults.conf
sed -i 's/^# spark.rapids.sql.enabled/spark.rapids.sql.enabled/' spark-conf/spark-defaults.conf
sed -i 's/^# spark.kryo.registrator/spark.kryo.registrator/' spark-conf/spark-defaults.conf

# Reiniciar servicios
docker compose restart spark-master spark-worker jupyter-lab
```

## ðŸ“Š Beneficios GPU vs CPU

### GPU Acelera (notebooks 03 y 04):
- âœ… Streaming con operaciones SQL complejas
- âœ… Aggregaciones en ventanas de tiempo
- âœ… Joins y shuffles grandes
- âœ… Parsing JSON de Kafka
- âœ… Window functions

### CPU es Suficiente para (notebook 02):
- âœ… Training batch de ML (Random Forest, GBT)
- âœ… Feature engineering con pandas/numpy
- âœ… Operaciones que no usan SQL DataFrame

## ðŸŽ¯ Arquitectura Final

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Jupyter Lab                       â”‚
â”‚              (Spark Driver + Notebooks)             â”‚
â”‚                    Port: 8888                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ spark://spark-master:7077
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Spark Master                       â”‚
â”‚              (Cluster Coordinator)                  â”‚
â”‚                 Ports: 8080, 7077                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Spark Worker                       â”‚
â”‚        (8 cores, 16GB RAM, GPU: RTX 3080)          â”‚
â”‚      Mode: CPU (GPU disabled temporalmente)        â”‚
â”‚                    Port: 8081                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Consume from
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Kafka                          â”‚
â”‚         Topic: statsbomb-360-events                 â”‚
â”‚            Rate: ~3000 events/sec                   â”‚
â”‚                 Ports: 9092, 9093                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–²
                          â”‚ Produce to
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Producer                         â”‚
â”‚     (StatsBomb 360 Event Stream Simulator)         â”‚
â”‚              Replay: Infinite loop                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“ ConfiguraciÃ³n Clave

### spark-defaults.conf (ConfiguraciÃ³n GPU Optimizada)
```properties
# RAPIDS ENABLED
spark.plugins                           com.nvidia.spark.SQLPlugin
spark.rapids.sql.enabled                true
spark.kryo.registrator                  com.nvidia.spark.rapids.GpuKryoRegistrator

# GPU Resources (Optimizado para 1 GPU)
spark.executor.resource.gpu.amount      1
spark.worker.resource.gpu.amount        1
spark.task.resource.gpu.amount          1.0    # CRITICAL: Full GPU per task
spark.cores.max                         4      # CRITICAL: Limit total cores to force 1 executor

# Resources
spark.executor.memory                   8g
spark.executor.cores                    4
spark.executor.instances                1
spark.driver.memory                     6g
```

**Por quÃ© esta configuraciÃ³n funciona:**
- `spark.task.resource.gpu.amount = 1.0` â†’ Cada task usa GPU completa (evita concurrencia)
- `spark.cores.max = 4` â†’ Solo 4 cores totales (fuerza 1 executor de 4 cores)
- `spark.executor.instances = 1` â†’ Garantiza solo 1 executor
- Resultado: 1 executor Ãºnico con acceso exclusivo a la GPU

## ðŸ” Troubleshooting

### Si los Executors Siguen Fallando

1. **Verificar memoria disponible:**
   ```bash
   docker stats --no-stream
   ```

2. **Verificar configuraciÃ³n GPU actual:**
   ```bash
   grep -E "spark.task.resource.gpu.amount|spark.cores.max" spark-conf/spark-defaults.conf
   ```
   Debe mostrar:
   ```
   spark.task.resource.gpu.amount          1.0
   spark.cores.max                         4
   ```

3. **Verificar GPU registrada en worker:**
   ```bash
   docker logs spark-worker 2>&1 | grep -A 2 "Custom resources"
   ```
   Debe mostrar:
   ```
   Custom resources for spark.worker:
   gpu -> [name: gpu, addresses: 0]
   ```

4. **Si aÃºn falla, reiniciar todo:**
   ```bash
   docker compose down
   docker compose up -d
   sleep 30
   ```

### Si pandas/PySpark Falla

```bash
docker exec jupyter-lab pip list | grep pandas
# Debe mostrar: pandas 1.5.3
```

Si no:
```bash
docker exec jupyter-lab pip install pandas==1.5.3
```

## ðŸ“ž Recursos y Enlaces

- **Spark Master UI:** http://localhost:8080
- **Spark Worker UI:** http://localhost:8081
- **Spark Application UI:** http://localhost:4040 (cuando job corre)
- **Jupyter Lab:** http://localhost:8888

- **Spark Docs:** https://spark.apache.org/docs/3.3.1/
- **RAPIDS Docs:** https://nvidia.github.io/spark-rapids/
- **StatsBomb API:** https://github.com/statsbomb/statsbombpy

---

**Estado:** âœ… Sistema completamente operativo
**Notebooks corregidos:** 02, 03, 04
**PrÃ³ximo paso:** Ejecutar notebooks 03 y 04 de streaming
**GPU:** Habilitada y lista para streaming
**Fecha:** 2025-11-06 (Actualizado)
